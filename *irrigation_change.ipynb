{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTdtgnjoV9ae7GuAI77Toy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlibeisel/pod_pou_lulcc/blob/main/*irrigation_change.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying Pivot Irrigated Land for Diversions\n",
        "\n",
        "By: Carli Beisel\n",
        "\n",
        "Adapted from David Ketchum (Github: dgketchum)\n",
        "\n",
        "Created on May 13, 2024\n",
        "\n",
        "Modified on May 17, 2024\n",
        "\n",
        "Purpose:\n",
        "\n",
        "1) Crop Irrigated Fields Shapefiles to each diversion in the Treasure Valley.\n",
        "\n",
        "2) Finds pivot irrigated areas in irrigation shapefile. This code assumes that circles/arcs in the landscape represent pivot irrigation. This script finds arcs in polygon geometries of the shapefile, and writes a new attribute called \"pivot\". This Script is directly from David Ketchum.\n",
        "\n",
        "3) Sums area of pivot irrigation for each shapefile and combines into one dataframe. The created dataframe that has two columns: year and total acres of pivot irrigation.\n",
        "\n",
        "4) Generates a regression plot of irrigation change over time with the genderated dataframe.\n",
        "\n",
        "5) Creates a new dataframe based on regression for input into the model."
      ],
      "metadata": {
        "id": "1PESNpPw12fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Crop Irrigated Fields Shapefiles to each diversion."
      ],
      "metadata": {
        "id": "hjhszncC2Ecm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWPOquMi1y3X"
      },
      "outputs": [],
      "source": [
        "# ------------------ #\n",
        "#  Import Libraries  #\n",
        "# ------------------ #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "! pip install pandarallel\n",
        "from pandarallel import pandarallel\n",
        "import glob\n",
        "import os\n",
        "from shapely.geometry import shape\n",
        "\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------ #\n",
        "#  Crop Irrigated Field Shapefile to Drains  #\n",
        "# ------------------------------------------ #\n",
        "\n",
        "drainsheds = gpd.read_file('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/drain_delineation/Drains_Merge_07072022.shp')\n",
        "names = drainsheds['Name']\n",
        "irrigated_field_files = glob.glob('/content/drive/MyDrive/Data/irrigation_shapefiles/irrigated_land_only/*.shp')\n",
        "output_dir = '/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigated_fields'\n",
        "\n",
        "# Create output directory if it does not exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Create function to crop shapefile to each drainshed area\n",
        "def crop_shapefiles(irrigated_field_files, drainsheds, output_dir):\n",
        "    mask_gdf = drainsheds\n",
        "    for field_file in irrigated_field_files:\n",
        "        input_gdf = gpd.read_file(field_file)\n",
        "        if input_gdf.crs != mask_gdf.crs:\n",
        "            input_gdf = input_gdf.to_crs(mask_gdf.crs)\n",
        "        for i, mask_feature in mask_gdf.iterrows():\n",
        "            mask_geom = mask_feature['geometry']\n",
        "            mask_name = mask_feature['Name']\n",
        "            cropped_gdf = gpd.overlay(input_gdf, gpd.GeoDataFrame(geometry=[mask_geom], crs=mask_gdf.crs), how='intersection')\n",
        "            field_name = os.path.splitext(os.path.basename(field_file))[0]\n",
        "            output_filename = os.path.join(output_dir, f\"{field_name}_{mask_name}_cropped.shp\")\n",
        "            cropped_gdf.to_file(output_filename)\n",
        "            print(f\"Cropped shapefile saved to {output_filename}\")\n",
        "\n",
        "crop_shapefiles(irrigated_field_files, drainsheds, output_dir)"
      ],
      "metadata": {
        "id": "UYBIjX_n2JyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Find pivot irrigated areas in each diversion's irrigation shapefile.\n",
        "\n",
        "This code assumes that circles/arcs in the landscape represent pivot irrigation. This script finds arcs in polygon geometries of the shapefile, and writes a new attribute called \"pivot\".\n",
        "\n",
        "This script is directly from David Ketchum."
      ],
      "metadata": {
        "id": "8NuaZD7C2QuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ #\n",
        "#  Import Libraries  #\n",
        "# ------------------ #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "! pip install pandarallel\n",
        "from pandarallel import pandarallel\n",
        "import glob\n",
        "import os\n",
        "from shapely.geometry import shape\n",
        "\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZUXEgsJG2Ouy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------ #\n",
        "#       Create Pivot_Test Function           #\n",
        "# ------------------------------------------ #\n",
        "\n",
        "min_arc = 10\n",
        "tol = 0.22\n",
        "\n",
        "def area_flood_irrigation(shp):\n",
        "    df = gpd.read_file(shp)\n",
        "    p = df[df['IType'] == 'P']['geometry']\n",
        "    p = np.sum([g.area for g in p])\n",
        "    s = df[df['IType'] == 'S']['geometry']\n",
        "    s = np.sum([g.area for g in s])\n",
        "    f = df[df['IType'] == 'F']['geometry']\n",
        "    f = np.sum([g.area for g in f])\n",
        "    t = p + s + f\n",
        "    print('pivot: {:.3f} sqkm, {:.3f}'.format(p / 1e6, p / t))\n",
        "    print('sprinkler: {:.3f} sqkm, {:.3f}'.format(s / 1e6, s / t))\n",
        "    print('flood: {:.3f} sqkm, {:.3f}'.format(f / 1e6, f / t))\n",
        "\n",
        "def bearing(a, b):\n",
        "    lat1 = np.radians(a[0])\n",
        "    lat2 = np.radians(b[0])\n",
        "\n",
        "    diffLong = np.radians(b[1] - a[1])\n",
        "\n",
        "    x = np.sin(diffLong) * np.cos(lat2)\n",
        "    y = np.cos(lat1) * np.sin(lat2) - (np.sin(lat1)\n",
        "                                       * np.cos(lat2) * np.cos(diffLong))\n",
        "\n",
        "    return np.arctan2(x, y)\n",
        "\n",
        "def find_arcs(g):\n",
        "    verts = g.exterior.coords\n",
        "    arc_ct, b_prev = 0, np.pi\n",
        "    for i, v in enumerate(verts):\n",
        "        try:\n",
        "            next = verts[i + 1]\n",
        "        except IndexError:\n",
        "            break\n",
        "        b = bearing(v, next)\n",
        "        diff = b - b_prev\n",
        "        if diff < tol:\n",
        "            arc_ct += 1\n",
        "            if arc_ct >= min_arc:\n",
        "                return True\n",
        "        else:\n",
        "            arc_ct = 0\n",
        "        b_prev = b\n",
        "\n",
        "    return False\n",
        "\n",
        "def pivot_test(in_shp, out_shp):\n",
        "    pandarallel.initialize(use_memory_fs=False, progress_bar=True)\n",
        "\n",
        "    df = gpd.read_file(in_shp).explode()\n",
        "    df.index = range(df.shape[0])\n",
        "    print('{} features'.format(df.shape[0]))\n",
        "    df['arc'] = df.geometry.apply(lambda g: find_arcs(g))\n",
        "    df['arc'] = df.geometry.parallel_apply(find_arcs)\n",
        "    df.to_file(out_shp, crs='epsg:4326')\n",
        "    print('{} of {} features have an arc'.format(np.count_nonzero(df['arc']), df.shape[0]))"
      ],
      "metadata": {
        "id": "OWwa9On92UGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------- #\n",
        "#        Run Pivot_Test for each Shapefile            #\n",
        "# --------------------------------------------------- #\n",
        "\n",
        "years = np.arange(1987,2022)\n",
        "files = glob.glob('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigated_fields/*.shp')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for file in files:\n",
        "       base_name = file.split('/')[-1].split('.')[0].replace('irrigated_', '')\n",
        "       base_name = base_name.replace('_cropped', '')  # Remove \"_cropped\"\n",
        "       for year in years:\n",
        "            out_shp = f'/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_pivot/{base_name}_arcs.shp'\n",
        "            pivot_test(file, out_shp)"
      ],
      "metadata": {
        "id": "fnUD3cpo2XA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sums area of pivot irrigated land and total irrigated land for each shapefile and combines into one dataframe.\n",
        "\n",
        "The created dataframe that has three columns: 1) year, 2) total pivot irrigated acres, and 3) total acres irrigated."
      ],
      "metadata": {
        "id": "Ypx9llaa2buu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------ #\n",
        "#   Import Libraries       #\n",
        "# ------------------------ #\n",
        "!pip install geopandas shapely\n",
        "import geopandas as gpd\n",
        "import glob\n",
        "import pandas as pd\n",
        "import re\n",
        "from shapely.geometry import MultiPolygon #for shapefiles with holes or difficult shapes\n",
        "import os\n",
        "\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7CSVPMDS2dGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------- #\n",
        "#   Sum Total Irrigated Area for Each Drainshed       #\n",
        "# --------------------------------------------------- #\n",
        "# Define a function to extract the year, name, and whether the file is cropped from the filename\n",
        "def parse_filename(filename):\n",
        "    base_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "    match = re.match(r'(\\d{4})_irrigated_(.*?)_cropped', base_name)\n",
        "    year = int(match.group(1))\n",
        "    name = match.group(2).replace('_', ' ')\n",
        "\n",
        "irrigated_fields = glob.glob('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigated_fields/*.shp'))\n",
        "\n",
        "irrigated_acres = []\n",
        "for shp in irrigated_fields:\n",
        "    year, name = parse_filename(shp)\n",
        "    gdf = gpd.read_file(shp)\n",
        "    total_area_acres = gdf['Acres'].sum()\n",
        "    irrigated_acres.append({'Year': year, 'Name': name, 'Total Irrigated Acres': total_area_acres})\n",
        "\n",
        "\n",
        "all_data = pd.DataFrame(irrigated_acres)\n",
        "\n",
        "all_data.to_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/all_irrigated_fields.csv', index=False)"
      ],
      "metadata": {
        "id": "SclKLOgS2fhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------- #\n",
        "#  Sum Total Pivot Irrigated Area for Each Drainshed  #\n",
        "# --------------------------------------------------- #\n",
        "\n",
        "\n",
        "# Define a function to extract the year and name from the filename\n",
        "def parse_filename(filename):\n",
        "    # Extract the base name without extension\n",
        "    base_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "    # Use regex to capture year and name\n",
        "    match = re.match(r'(\\d{4})_(.*?)_arcs', base_name)\n",
        "    if match:\n",
        "        year = int(match.group(1))\n",
        "        name = match.group(2).replace('_', ' ')\n",
        "        return year, name\n",
        "    return None, None\n",
        "\n",
        "# List all shapefiles in the input folder\n",
        "shapefiles = glob.glob('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_pivot/*.shp')\n",
        "\n",
        "# Initialize a list to store data\n",
        "irrigated_acres = []\n",
        "\n",
        "# Iterate over each shapefile\n",
        "for shp in shapefiles:\n",
        "    year, name = parse_filename(shp)\n",
        "    gdf = gpd.read_file(shp)\n",
        "    total_area_acres = gdf['arc'].sum()\n",
        "    irrigated_acres.append({'Year': year, 'Name': name, 'Pivot Irrigated Acres': total_area_acres})\n",
        "\n",
        "pivot_data = pd.DataFrame(irrigated_acres)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "pivot_data.to_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/pivot_irrigated_fields.csv', index=False)"
      ],
      "metadata": {
        "id": "cbevBvCe2hyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------- #\n",
        "#  Combine Dataframes & Calculate Proportion Metric   #\n",
        "# --------------------------------------------------- #\n",
        "\n",
        "pivot = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/pivot_irrigated_fields.csv')\n",
        "all = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/all_irrigated_fields.csv')\n",
        "\n",
        "#Manually replace name of Drainage District No. 3\n",
        "all['Name'] = all['Name'].replace({'Drainage District No. 3': 'Drainage District No. 3'})\n",
        "pivot['Name'] = pivot['Name'].replace({'Drainage District No': 'Drainage District No. 3'})\n",
        "\n",
        "\n",
        "merged_data = pd.merge(pivot, all, on=['Year', 'Name'], how='inner')\n",
        "print(merged_data)\n",
        "\n",
        "merged_data['Pivot Proportion'] = merged_data['Pivot Irrigated Acres'] / merged_data['Total Irrigated Acres']\n",
        "print(merged_data)\n",
        "merged_data.to_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigation_change.csv', index=False)"
      ],
      "metadata": {
        "id": "xP7raJGQ2kN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generate a regression plot of irrigation change over time for each drainshed."
      ],
      "metadata": {
        "id": "WvKX8pbc2ZNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------ #\n",
        "#   Import Libraries       #\n",
        "# ------------------------ #\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qn1eSwoH2mXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------ #\n",
        "#  Read in Dataframe and Define Varaibles    #\n",
        "# ------------------------------------------ #\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigation_change.csv')\n",
        "\n",
        "names = df['Name'].unique()\n",
        "year = df['Year']\n",
        "\n",
        "prop = df['Pivot Proportion']"
      ],
      "metadata": {
        "id": "iO6yh6ZG2rfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- #\n",
        "#  Plot for each Diversion   #\n",
        "# -------------------------- #\n",
        "\n",
        "names = df['Name'].unique()\n",
        "grouped = df.groupby('Name')\n",
        "\n",
        "# Iterate over each unique name\n",
        "for i in names:\n",
        "    temp_df = grouped.get_group(i)\n",
        "\n",
        "    # Extract the year and proportion for plotting\n",
        "    year = temp_df['Year']\n",
        "    prop = temp_df['Pivot Proportion']\n",
        "\n",
        "    plt.plot(year, prop, 'o', markersize=5)\n",
        "    plt.title(f\"{i}\")\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Proportion of Pivot Irrigated Land')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "T1rNxL6Y2tP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------- #\n",
        "#  Plot for ALL Drainsheds   #\n",
        "# -------------------------- #\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/drainshed_irrigation_change.csv')\n",
        "\n",
        "grouped = df.groupby('Name')\n",
        "year = df['Year']\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Loop through the grouped data\n",
        "for year, data in grouped:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=data['Year'],\n",
        "        y=data['Pivot Proportion'],\n",
        "        mode='lines',\n",
        "        name=str(year)\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Irrigation Change in the Treasure Valley\",\n",
        "    xaxis=dict(title='Year'),\n",
        "    yaxis=dict(title='Proportion')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xoFDGXXk3uOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------ #\n",
        "#  Regresion plot for each Drainshed   #\n",
        "# ------------------------------------ #\n",
        "\n",
        "# Group the data by 'Name' or any other relevant column\n",
        "grouped = df.groupby('Name')\n",
        "\n",
        "# Create a directory to save the plots if it doesn't exist\n",
        "output_dir = '/content/drive/MyDrive/Data/Model Modifications/irrigation_change/Figures/drainshed_regressions/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Iterate over each group\n",
        "for name, group in grouped:\n",
        "    # Initialize and fit the linear regression model for each group\n",
        "    model = LinearRegression()\n",
        "    X = group[['Year']]\n",
        "    y = group['Pivot Proportion']\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predict values using the fitted model\n",
        "    group['Predicted_Acres'] = model.predict(X)\n",
        "\n",
        "    # Calculate the R² value\n",
        "    r_squared = model.score(X, y)\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(data=group, x='Year', y='Pivot Proportion', marker='o', label='Actual Data')\n",
        "    plt.plot(group['Year'], group['Predicted_Acres'], color='red', label='Regression Line')\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.title(f'Regression for {name}')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Proportion of Land Irrigated with Pivot')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Annotate the R² value on the plot\n",
        "    plt.text(\n",
        "        0.05, 0.85, f'R²: {r_squared:.2f}',\n",
        "        transform=plt.gca().transAxes, fontsize=12, verticalalignment='top'\n",
        "    )\n",
        "\n",
        "    plot_filename = f'{name}_regression.tiff'\n",
        "    plt.savefig(os.path.join(output_dir, plot_filename), format='tiff', dpi=300)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "KMVdH5t-3wRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Create dataframe from regression data for input into GLMM model"
      ],
      "metadata": {
        "id": "-Oq6yCDr3zFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------- #\n",
        "#  Build Data off of Regression for Model   #\n",
        "# ----------------------------------------- #\n",
        "\n",
        "grouped = df.groupby('Name')\n",
        "\n",
        "all_predictions = pd.DataFrame()\n",
        "\n",
        "for name, group in grouped:\n",
        "    # Initialize and fit the linear regression model for each group\n",
        "    model = LinearRegression()\n",
        "    X = group[['Year']]\n",
        "    y = group['Pivot Proportion']\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predict values for the years 1987 to 2022\n",
        "    future_years = pd.DataFrame({'Year': np.arange(1987, 2023)})\n",
        "    predicted_proportions = model.predict(future_years)\n",
        "\n",
        "    # Create a DataFrame for the predictions\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'Year': future_years['Year'],\n",
        "        'Name': name,\n",
        "        'Predicted_Proportion': predicted_proportions\n",
        "    })\n",
        "\n",
        "    # Append the predictions to the overall DataFrame\n",
        "    all_predictions = pd.concat([all_predictions, predictions_df], ignore_index=True)\n",
        "\n",
        "all_predictions.to_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/irrigation_model_input.csv', index=False)"
      ],
      "metadata": {
        "id": "m1IB-9oa31uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------- #\n",
        "#  Rename Drains to Match Dataset   #\n",
        "# --------------------------------- #\n",
        "# inputted because old data set wasn't merging correctly with model input\n",
        "\n",
        "file = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/irrigation_change/irrigation_model_input.csv')\n",
        "\n",
        "def rename_names_in_csv(input_csv_path, output_csv_path, name_mapping):\n",
        "    \"\"\"\n",
        "    Rename names in the 'Name' column of a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    input_csv_path (str): Path to the input CSV file.\n",
        "    output_csv_path (str): Path to save the modified CSV file.\n",
        "    name_mapping (dict): Dictionary where keys are old names and values are new names.\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_csv_path)\n",
        "    if 'Name' not in df.columns:\n",
        "        raise ValueError(\"The CSV file does not contain a 'Name' column.\")\n",
        "    df['Name'] = df['Name'].replace(name_mapping)\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"CSV file with updated names saved to {output_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = '/content/drive/MyDrive/Data/Model Modifications/irrigation_change/irrigation_model_input.csv'\n",
        "    output_csv = '/content/drive/MyDrive/Data/Model Modifications/irrigation_change/irrigation_model_input2.csv'\n",
        "\n",
        "    # Dictionary with old names as keys and new names as values\n",
        "    name_changes = {\n",
        "        'Dixie drain': 'Dixie Drain',\n",
        "        'Drainage District No. 3': 'Drainage District No3',\n",
        "        'West Hartley': 'West Hartley Gulch',\n",
        "        'East Hartley Drain': 'East Hartley Gulch'\n",
        "    }\n",
        "\n",
        "    rename_names_in_csv(input_csv, output_csv, name_changes)"
      ],
      "metadata": {
        "id": "WZb7QYl-34u1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}