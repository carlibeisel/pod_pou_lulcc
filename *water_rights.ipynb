{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtGqho7xqzSCQ70rIbWr4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlibeisel/pod_pou_lulcc/blob/main/*water_rights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Water Rights in the Treasure Valley for Diversions\n",
        "\n",
        "By: Carli Beisel\n",
        "\n",
        "\n",
        "Created on August 2024\n",
        "\n",
        "\n",
        "Purpose:\n",
        "\n",
        "1) Crop Water Rights layer to drainshds in the Treasure Valley and also create a separate file that organizes all WR based on priorty year + surface/groundwater.\n",
        "\n",
        "\n",
        "2) Create a figure showing the difference between surface + groundwater rights in diversions.\n"
      ],
      "metadata": {
        "id": "29Y7ebNX4Vkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Organize IDWR Water Right Data from GIS Data Hub\n",
        "\n",
        "Separate based on surface/groundwater rights and organize based on priority year.  "
      ],
      "metadata": {
        "id": "Skl6N7414arW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "059Jji5G4Jqs"
      },
      "outputs": [],
      "source": [
        "# -------------------- #\n",
        "#   Import Packages    #\n",
        "# -------------------- #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#     Rename Drains in LBRB           #\n",
        "# ----------------------------------- #\n",
        "\n",
        "# Function to rename names in the 'Name' column of a shapefile\n",
        "def rename_names_in_shapefile(shapefile_path, output_path, name_mapping):\n",
        "    \"\"\"\n",
        "    Rename names in the 'Name' column of a shapefile.\n",
        "\n",
        "    Parameters:\n",
        "    shapefile_path (str): Path to the input shapefile.\n",
        "    output_path (str): Path to save the modified shapefile.\n",
        "    name_mapping (dict): Dictionary where keys are old names and values are new names.\n",
        "\n",
        "    \"\"\"\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "    if 'Name' not in gdf.columns:\n",
        "        raise ValueError(\"The shapefile does not contain a 'Name' column.\")\n",
        "    gdf['Name'] = gdf['Name'].replace(name_mapping)\n",
        "    gdf.to_file(output_path)\n",
        "    print(f\"Shapefile with updated names saved to {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shapefile = '/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/drain_delineation/Drains_Merge_07072022.shp'\n",
        "    output_shapefile = '/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/drain_delineation/Drains_08162024.shp'\n",
        "\n",
        "    # Dictionary with old names as keys and new names as values\n",
        "    name_changes = {\n",
        "        'Dixie drain': 'Dixie Drain',\n",
        "        'East Hartley Drain': 'East Hartley Gulch',\n",
        "        'West Hartley': 'West Hartley Gulch',\n",
        "        'Drainage District No. 3': 'Drainage District No3'\n",
        "    }\n",
        "\n",
        "    rename_names_in_shapefile(input_shapefile, output_shapefile, name_changes)"
      ],
      "metadata": {
        "id": "z9XEPsgw4diC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#         Crop to the LBRB            #\n",
        "# ----------------------------------- #\n",
        "water_rights = gpd.read_file('/content/drive/MyDrive/Data/Model Modifications/water_rights/WaterRightPOUs/WaterRightPOUs.shp')\n",
        "lbrb = gpd.read_file('/content/drive/MyDrive/Data/GIS Shapefiles/LBRB_shp/LBRB_file.shp')\n",
        "\n",
        "lbrb_water_rights = gpd.overlay(water_rights, lbrb, how='intersection')\n",
        "\n",
        "lbrb_water_rights.to_file('/content/drive/MyDrive/Data/Model Modifications/water_rights/wr_lbrb_masked/lbrb_water_rights.shp')"
      ],
      "metadata": {
        "id": "MHYsj6Fk4i7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#       Convert .SHP to .CSV          #\n",
        "# ----------------------------------- #\n",
        "lbrb_water_rights = gpd.read_file('/content/drive/MyDrive/Data/Model Modifications/water_rights/lbrb_water_rights/lbrb_water_rights.shp')\n",
        "\n",
        "wr = pd.DataFrame(water_rights.drop(columns='geometry'))\n",
        "wr.to_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/lbrb_water_rights.csv', index=False)"
      ],
      "metadata": {
        "id": "qkel0oZc4lPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#       Crop WR to Drainsheds         #\n",
        "# ----------------------------------- #\n",
        "water_rights = gpd.read_file('/content/drive/MyDrive/Data/Model Modifications/water_rights/WaterRightPOUs/WaterRightPOUs.shp')\n",
        "drainsheds = gpd.read_file('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/drain_delineation/Drains_08162024.shp')\n",
        "names = drainsheds['Name']\n",
        "water_rights = water_rights.to_crs(drainsheds.crs)\n",
        "output_dir = '/content/drive/MyDrive/Data/Model Modifications/water_rights/wr_drainshed_masked/'\n",
        "\n",
        "# Create function to crop water rights to each drainshed area\n",
        "def crop_water_rights_to_drainsheds(water_rights, drainsheds, output_dir):\n",
        "    mask_gdf = drainsheds\n",
        "    for i, mask_feature in mask_gdf.iterrows():\n",
        "        mask_geom = mask_feature['geometry']\n",
        "        mask_name = mask_feature['Name']\n",
        "\n",
        "        cropped_gdf = gpd.overlay(water_rights, gpd.GeoDataFrame(geometry=[mask_geom], crs=mask_gdf.crs), how='intersection')\n",
        "\n",
        "        output_filename = os.path.join(output_dir, f\"{mask_name}_wr.shp\")\n",
        "\n",
        "        # Save the cropped shapefile\n",
        "        cropped_gdf.to_file(output_filename)\n",
        "        print(f\"Cropped shapefile saved to {output_filename}\")\n",
        "\n",
        "crop_water_rights_to_drainsheds(water_rights, drainsheds, output_dir)\n"
      ],
      "metadata": {
        "id": "e2S3iei74oMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#   Convert Drain WR to CSV File      #\n",
        "# ----------------------------------- #\n",
        "\n",
        "shapefiles = glob.glob('/content/drive/MyDrive/Data/Model Modifications/water_rights/wr_drainshed_masked/*.shp')\n",
        "\n",
        "csv_output_dir = '/content/drive/MyDrive/Data/Model Modifications/water_rights/wr_drainshed_masked/'\n",
        "for shapefile in shapefiles:\n",
        "    gdf = gpd.read_file(shapefile)\n",
        "    base_name = os.path.basename(shapefile)\n",
        "    drainshed_name = base_name.split('_wr')[0]  # Extracting the part before '_wr'\n",
        "    gdf['Drainshed'] = drainshed_name #add a column for each drainshed name\n",
        "    csv_filename = os.path.splitext(base_name)[0] + '.csv'\n",
        "    csv_filepath = os.path.join(csv_output_dir, csv_filename)\n",
        "    gdf.to_csv(csv_filepath, index=False)\n",
        "    print(f\"Converted {shapefile} to {csv_filepath} with added 'Drainshed' column.\")"
      ],
      "metadata": {
        "id": "CZCrIUTQ4qms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------- #\n",
        "#      Merge drainhed WRs into one file     #\n",
        "# ----------------------------------------- #\n",
        "\n",
        "csv_files = glob.glob('/content/drive/MyDrive/Data/Model Modifications/water_rights/wr_drainshed_masked/*.csv')\n",
        "df_list = []\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df_list.append(df)\n",
        "merged_df = pd.concat(df_list, ignore_index=True)\n",
        "merged_df.to_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv', index=False)\n",
        "\n",
        "#add in new column to separate GW from SW\n",
        "file = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv')\n",
        "file['Type'] = file['Source'].apply(lambda x: 'GW' if x == 'GROUND WATER' else 'SW')\n",
        "file.to_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv', index=False)"
      ],
      "metadata": {
        "id": "1pf-42w74t2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ #\n",
        "#      Drain WRs Model Input     #\n",
        "# ------------------------------ #\n",
        "# based on SW + GW + total\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'PriorityDa' column to datetime format and extract the year\n",
        "df['PriorityDa'] = pd.to_datetime(df['PriorityDa'], format='%Y-%m-%d', errors='coerce')\n",
        "df['Year'] = df['PriorityDa'].dt.year\n",
        "\n",
        "# Group by year, type, and drainage area (assuming 'Drainshed' is the column for drainage)\n",
        "yearly_priority_counts = df.groupby(['Year', 'Type', 'Drainshed']).agg({'PriorityDa': 'nunique'}).reset_index()\n",
        "yearly_priority_counts.rename(columns={'PriorityDa': 'Water Rights'}, inplace=True)\n",
        "\n",
        "# Pivot the table to create separate columns for GW and SW water rights for each drainage\n",
        "pivot_counts = yearly_priority_counts.pivot_table(index=['Year', 'Drainshed'], columns='Type', values='Water Rights', fill_value=0).reset_index()\n",
        "\n",
        "pivot_counts.columns = ['Year', 'Drainshed', 'GW Water Rights', 'SW Water Rights']\n",
        "\n",
        "# Add a column for total water rights (GW + SW)\n",
        "pivot_counts['Total Water Rights'] = pivot_counts['GW Water Rights'] + pivot_counts['SW Water Rights']\n",
        "\n",
        "# Calculate cumulative water rights (GW, SW, Total) for each drainage area individually\n",
        "pivot_counts['gw_wr'] = pivot_counts.groupby('Drainshed')['GW Water Rights'].cumsum()\n",
        "pivot_counts['sw_wr'] = pivot_counts.groupby('Drainshed')['SW Water Rights'].cumsum()\n",
        "pivot_counts['total_wr'] = pivot_counts.groupby('Drainshed')['Total Water Rights'].cumsum()\n",
        "\n",
        "# Create a new DataFrame that stores this information\n",
        "wr_final = pivot_counts\n",
        "\n",
        "columns_to_save = [\n",
        "    'Year',         # Year\n",
        "    'Drainshed',               # Drainage area\n",
        "    'gw_wr',    # Cumulative Groundwater Water Rights\n",
        "    'sw_wr',    # Cumulative Surface Water Rights\n",
        "    'total_wr'  # Cumulative Total Water Rights\n",
        "]\n",
        "\n",
        "# Save the selected columns to a new CSV file\n",
        "output_file_path = '/content/drive/MyDrive/Data/Model Modifications/water_rights/final_wr.csv'\n",
        "wr_final[columns_to_save].to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "HM05KvpD4wFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figures"
      ],
      "metadata": {
        "id": "8DsTGzuO47nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#   SW/GW Comparison in Drainsheds\n",
        "#       Decreed Year\n",
        "# ----------------------------------- #\n",
        "\n",
        "#violin plot of all drainages\n",
        "\n",
        "file = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv')\n",
        "\n",
        "# Convert DecreedDat to datetime format and get year\n",
        "file['DecreedDat'] = pd.to_datetime(file['DecreedDat'])\n",
        "file['DecreedYear'] = file['DecreedDat'].dt.year\n",
        "\n",
        "plot = sns.catplot(\n",
        "    data=file, x=\"Drainshed\", y=\"DecreedYear\", hue=\"Type\",\n",
        "    kind=\"violin\", height=8, aspect=2)  # Increase height and aspect ratio for larger plot\n",
        "\n",
        "plot.set_xticklabels(rotation=45, ha='right')\n",
        "plot.fig.suptitle(\"Distribution of Water Rights for Drainshed by Decreed Year\", fontsize=16)\n",
        "plot.fig.subplots_adjust(top=0.9)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4ZHxepW49at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------- #\n",
        "#   SW/GW Comparison in Drainsheds\n",
        "#       Priority Year\n",
        "# ----------------------------------- #\n",
        "\n",
        "#violin plot of all drainages\n",
        "\n",
        "# Load the data\n",
        "file = pd.read_csv('/content/drive/MyDrive/Data/Model Modifications/water_rights/drainsheds_wr.csv')\n",
        "\n",
        "# Convert DecreedDat to datetime format\n",
        "file['PriorityDa'] = pd.to_datetime(file['PriorityDa'])\n",
        "\n",
        "# Extract the year from DecreedDat\n",
        "file['PriorityYear'] = file['PriorityDa'].dt.year\n",
        "\n",
        "# Plot using sns.catplot\n",
        "plot = sns.catplot(\n",
        "    data=file, x=\"Drainshed\", y=\"PriorityYear\", hue=\"Type\",\n",
        "    kind=\"violin\", height=8, aspect=2)  # Increase height and aspect ratio for larger plot\n",
        "\n",
        "plot.set_xticklabels(rotation=45, ha='right')\n",
        "plot.fig.suptitle(\"Distribution of Water Rights for Drainshed by Priority Year\", fontsize=16)\n",
        "plot.fig.subplots_adjust(top=0.9)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWo62h1L5Eqr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}