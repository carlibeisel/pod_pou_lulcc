for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('class1_urban',
'class2_crops',
'contagion',
'largest_patch_index')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- (data[,i])/100
}
tt <- table(data$Name)
data <- subset(data, Name %in% names(tt[tt>4]))
write.csv(data, '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv', row.names = FALSE)
# With zeros data
data <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0531.csv')
data <- data[!duplicated(data[c('Name', 'Year')]),] #remove duplicates
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('class1_urban',
'class2_crops',
'contagion',
'largest_patch_index')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- (data[,i])/100
}
tt <- table(data$Name)
data <- subset(data, Name %in% names(tt[tt>4]))
# Storage data
data$perc_used <- ifelse(data$AF_available > 0, data$AF_used/data$AF_available, NA)
data$wr_storage <- ifelse(data$AF_available >0, 1, 0)
write.csv(data, '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0531.csv', row.names = FALSE)
# Import the dataset to work with
div <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv')
div$lt <- log(div$Acre_feet)
div_arma <- subset(div, (Acre_feet > 0.00001))
div_arma$lt <- log(div_arma$Acre_feet)
names <- unique(div_arma$Name)
# Find diversions with less than 34 years worth of data, and remove if there
# are data gaps, or if discharge for a given year in the middle was 0
for (i in names){
sub <- subset(div_arma, Name == i)
if (length(sub$Acre_feet) < 34){
print(i)
print(length(sub$Acre_feet))
}
}
remove <- c("Barber pumps",
"Mace-Mace Canal",
"River Run",
"Surprise Valley and Micron",
"Thomas Aiken Canal",
"Warm Springs Canal",
'Ester Simplot',
"Stutheit",
"Riverside Village",
"McCurry Pump",
"Golden Gate Canal",
"Capitol View Canal",
"Shakespeare",
"Suez")
div_arma <- subset(div_arma, !(Name %in% remove))
# Check after removal to ensure continuous datasets
names <- unique(div_arma$Name)
for (i in names){
sub <- subset(div_arma, Name == i)
if (length(sub$Acre_feet) < 34){
print(i)
print(length(sub$Acre_feet))
}
}
# Need change in a groups for a test, filter out groups with no change in urban proportion
ll.test <- div_arma %>%
group_by(Name) %>%
filter((max(class1_urban) - min(class1_urban)) > 0) %>%
ungroup()
# Need change in a groups for a test, filter out groups that use no storage over whole time period
# for stationarity test
ll.use <- div_arma %>%
group_by(Name) %>%
filter((max(AF_used) - min(AF_used)) > 0) %>%
ungroup()
# Panel dataframe for test
new_use <- pdata.frame(ll.use, index = c('Name', 'Year'))
new_use$AF_used <- as.numeric(new_use$AF_used) # change from integer to numeric for test
new_urb <- pdata.frame(ll.test, index = c('Name', 'Year'))
new <-pdata.frame(div_arma, index = c('Name', 'Year'))
urb.test <- purtest(new_urb$class1_urban, data = new_urb, lags = 'AIC', test = 'levinlin') #non-stationary
use.test <- purtest(new_use$AF_used, data = new_use, lags = 'AIC', test = 'levinlin') #non-stationary
lt.test <- purtest(new$lt, data = new, lags ='AIC', test = 'levinlin')
AF.test <- purtest(new$Acre_feet, data = new, lags = 'AIC', test = 'levinlin')
temp.test <- purtest(new$irrig_temp, data = new, lags = 'AIC', test = 'levinlin')
prcp.test <- purtest(new$annual_prcp, data = new, lags = 'AIC', test = 'levinlin') #non-stationary
et.test <- purtest(new$et, data = new, lags = 'AIC', test = 'levinlin') # non-stationary
arma_input <- div_arma %>%
select(Name, Year, Acre_feet, irrig_temp, annual_prcp, AF_used, class1_urban, et, lt)
arma_input = arma_input %>%
group_by(Name) %>%
mutate(d.et = c(NA, diff(et)),
d.urb = c(NA, diff(class1_urban)),
d.use = c(NA, diff(AF_used)),
d.prcp = c(NA, diff(annual_prcp)),
d.temp = c(NA, diff(irrig_temp)),
d.Acre_feet = c(NA, diff(Acre_feet))) %>%
ungroup()
arma_input <- na.omit(arma_input)
# Make sure everything is numeric
arma_input$d.et <- as.numeric(arma_input$d.et)
arma_input$d.temp <- as.numeric(arma_input$d.temp)
arma_input$d.use <- as.numeric(arma_input$d.use)
arma_input$d.Acre_feet <- as.numeric(arma_input$d.Acre_feet)
arma_input$d.urb <- as.numeric(arma_input$d.urb)
arma_input$d.prcp <- as.numeric(arma_input$d.prcp)
# Need change in a groups for a test, filter out groups with no change in urban proportion
ll.test <- arma_input %>%
group_by(Name) %>%
filter((max(class1_urban) - min(class1_urban)) > 0) %>%
ungroup()
# Need change in a groups for a test, filter out groups that use no storage over whole time period
# for stationarity test
ll.use <- arma_input %>%
group_by(Name) %>%
filter((max(AF_used) - min(AF_used)) > 0) %>%
ungroup()
new_use <- pdata.frame(ll.use, index = c('Name', 'Year'))
new_use$d.use <- as.numeric(new_use$d.use)
new_urb <- pdata.frame(ll.test, index = c('Name', 'Year'))
new <-pdata.frame(arma_input, index = c('Name', 'Year'))
et.test <- purtest(new$d.et, data = new, lags = 'AIC', test = 'levinlin') #stationary
urb.test <- purtest(new_urb$d.urb, data = new_urb, lags = 'AIC', test = 'levinlin') #stationary
use.test <- purtest(new_use$d.use, data = new_use, lags = 'AIC', test = 'levinlin') #stationary
AF.test <- purtest(new$d.Acre_feet, data = new, lags = 'AIC', test = 'levinlin')
prcp.test <- purtest(new$d.prcp, data = new, lags = 'AIC', test = 'levinlin')
temp.test <- purtest(new$d.temp, data = new, lags = 'AIC', test = 'levinlin')
# Standardize all variables before exporting
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
vars <- c('d.use',
'd.urb',
'd.prcp',
'd.temp',
'd.et')
for (i in vars){
var <- colnames(arma_input[i])
new_col_name <- paste('scale_', var, sep='')
col <- arma_input %>% select(i)
arma_input[new_col_name] <- scale2sd(unlist(arma_input[,i]))
}
# Export data for model in borah
write.csv(arma_input, file = '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/arma_input_0531.csv')
div <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv')
div$lt <- log(div$Acre_feet)
div <- subset(div, (Acre_feet > 0.00001)) # Remove data that has 0
str(div2)
# Import file with Quinns Pond and Caldwell Lowline
div2 <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0531.csv')
div2$lt <- log(div2$Acre_feet)
sel.name <- c("Quinns Pond", 'Caldwell Lowline Canal')
div2 <- subset(div2, Name %in% sel.name)
div_new <- rbind(div,div2)
div_new <- div_new %>%
select(Year, Name, Acre_feet, class1_urban, et, lt, AF_used, annual_prcp, irrig_temp) #changed from irrig_prcp to annual_prcp
# Scale response variables
vars <- c('class1_urban',
'et',
'AF_used',
'annual_prcp', #changed from irrig_prcp to annual_prcp
'irrig_temp')
for (i in vars){
var <- colnames(div_new[i])
new_col_name <- paste('scale_', var, sep='')
col <- div_new %>% select(i)
div_new[new_col_name] <- scale2sd(unlist(div_new[,i]))
}
# Export data for model in borah
write.csv(div_new, file = '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/glmm_input_0531.csv')
library(brms) # Do bayesian models, use function brm
library(tidyverse) #
library(dplyr)
library(readr)
library(tibble)
library(ggrepel)
library(flexmix)
library(modelr)
print('Import diversion data for ARMA model')
diversions <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/arma_input_0531.csv')
diversions <- diversions[!duplicated(diversions[c('Name', 'Year')]),] #remove duplicates
diversions <- na.omit(diversions)
print('Model with ARMA')
priors <- c(
set_prior('normal(0,1)', class = 'Intercept'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_d.urb'),
set_prior('gamma(1,1)', class = 'sd'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_d.use'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_d.prcp'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_d.temp'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_d.et'),
set_prior('lkj_corr_cholesky(2)', class = 'L')
)
print('Create model with ARMA terms and student-t family')
# brms is used to run mixed effects models
AF.arma.stud <- brms::brm(lt ~ (1 + scale_d.urb | Name) + scale_d.urb + scale_d.prcp + scale_d.temp + scale_d.et + scale_d.use + arma(gr = Name),
data = diversions,
family = 'student',
prior = priors,
iter = 4000,
control = list(max_treedepth = 20,
adapt_delta = 0.999),
cores = getOption('mc.cores', parallel::detectCores()))
summary(AF.arma.stud)
saveRDS(AF.arma.stud, file = '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/mod-arma-stud.RDS')
# Read in the data for model with no ARMA
diversions <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/glmm_input_0531.csv')
print(c('This is the length before removing duplicates', length(diversions$Acre_feet)))
diversions <- diversions[!duplicated(diversions[c('Name', 'Year')]),] #remove duplicates
print(length(diversions$Acre_feet))
# Priors
priors <- c(
set_prior('normal(0,1)', class = 'Intercept'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_class1_urban'),
set_prior('gamma(1,1)', class = 'sd'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_annual_prcp'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_irrig_temp'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_et'),
set_prior('normal(0,1)', class = 'b', coef = 'scale_AF_used')
)
print('Create model without ARMA terms')
AF.mix <- brm(Acre_feet ~ (1 + scale_class1_urban | Name) + scale_class1_urban + scale_annual_prcp + scale_irrig_temp + scale_et + scale_AF_used,
data = diversions,
family = 'lognormal',
prior = priors,
iter = 4000,
control = list(max_treedepth = 20,
adapt_delta = 0.999),
cores = getOption('mc.cores', parallel::detectCores()))
summary(AF.mix)
saveRDS(AF.mix, file = '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/mod-mix.RDS')
library(brms) # work with outputs of GLMMs
library(bayesplot) # built in plots with brms
library(tidybayes) # get clean draws from brms object
library(modelr) # model manipulation for visualization
library(dplyr) # dataframe manipulation
library(tidyverse)
# Load the data and the model
df.arma <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/arma_input_0531.csv')
mod.arma <- readRDS('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/mod-arma-stud.RDS')
# Unscale function
unscale <- function(x, orig){
unscaled <- (sd(orig)*2*x)+mean(orig)
return(unscaled)
}
# Epreds for precipitaiton
print('Epreds for precipitaiton')
new = df.arma %>%
data_grid(scale_d.urb = mean(scale_d.urb),
scale_d.et = mean(scale_d.et),
scale_d.prcp = seq_range(scale_d.prcp, n = 200),
scale_d.temp = mean(scale_d.temp),
scale_d.use = mean(scale_d.use),
Year = Year)
new$Name <- NA
# Expected predicted draws
epreddraws <- add_epred_draws(mod.arma,
newdata=new,
ndraws=1000,
re_formula=NA)
epreddraws$unscale.prcp <- unscale(epreddraws$scale_d.prcp, df.arma$d.prcp)
print('success drawing predictions')
out_file <- paste('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/epred_prcp.csv')
write.csv(epreddraws, file = out_file)
print('Epreds for temp')
new = df.arma %>%
data_grid(scale_d.urb = mean(scale_d.urb),
scale_d.et = mean(scale_d.et),
scale_d.prcp = mean(scale_d.prcp),
scale_d.temp = seq_range(scale_d.temp, n = 200),
scale_d.use = mean(scale_d.use),
Year = Year)
new$Name <- NA
epreddraws <-  add_epred_draws(mod.arma,
newdata=new,
ndraws=1000,
re_formula=NA)
epreddraws$unscale.temp <- unscale(epreddraws$scale_d.temp, df.arma$d.temp)
print('success drawing predictions')
out_file <- paste('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/epred_temp.csv')
write.csv(epreddraws, file = out_file)
print('Epred draws for AF used')
new = df.arma %>%
data_grid(scale_d.urb = mean(scale_d.urb),
scale_d.et = mean(scale_d.et),
scale_d.prcp = mean(scale_d.prcp),
scale_d.temp = mean(scale_d.temp),
scale_d.use = seq_range(scale_d.use, n = 200),
Year = Year)
new$Name <- NA
epreddraws <-  add_epred_draws(mod.arma,
newdata=new,
ndraws=1000,
re_formula=NA)
epreddraws$unscale.use <- unscale(epreddraws$scale_d.use, df.arma$d.use)
print('success drawing predictions')
out_file <- paste('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/epred_use.csv')
write.csv(epreddraws, file = out_file)
print('epred draws for ET')
new = df.arma %>%
data_grid(scale_d.urb = mean(scale_d.urb),
scale_d.et = seq_range(scale_d.et, n = 200),
scale_d.prcp = mean(scale_d.prcp),
scale_d.temp = mean(scale_d.temp),
scale_d.use = mean(scale_d.use),
Year = Year)
new$Name <- NA
epreddraws <-  add_epred_draws(mod.arma,
newdata=new,
ndraws=1000,
re_formula=NA)
epreddraws$unscale.et <- unscale(epreddraws$scale_d.et, df.arma$d.et)
print('success drawing predictions')
out_file <- paste('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/epred_et.csv')
write.csv(epreddraws, file = out_file)
## Import packages
library(brms)
library(Matrix)
library(tidyverse)
library(dplyr)
## Import data
div <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv')
div <- div[!duplicated(div[c('Name', 'Year')]),] #remove duplicates
div <- subset(div, (Acre_feet > 0.00001)) # Remove data that has 0
div_new <- subset(div, !(Name == 'Ester Simplot')) #Removes short dataframe
mae <- function(model, data_compare){
yhat <- (posterior_predict(model))
resid <- sweep(yhat,
2,
data_compare,
FUN="-")
return(mean(abs(resid)))
}
## Scaling function for variables
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
## Build function to run all diverisons through
mlr_brm <- function(data, name) {
#Subset data to an individual canal
sub_data <- subset(data, Name == name)
# Select only variables going into the model
sub_data <- sub_data[,c('Acre_feet',
'scale_class1_urban',
'annual_prcp',
'irrig_temp',
'et',
'AF_used')]
#Select variables to scale around mean
vars_scale <- c('annual_prcp',
'irrig_temp')
#Scale variables
for (i in vars_scale){
var_name <- i
sub_data[var_name] <- scale2sd(sub_data[,i])
}
# If storage water use is not 0, scale the variable
if (mean(sub_data$AF_used) != 0){
sub_data$AF_used <- scale2sd(sub_data$AF_used)
}
# Run the linear regression
and_mod<-brm(Acre_feet ~ scale_class1_urban + et + annual_prcp + irrig_temp + AF_used,
data=sub_data,
family = 'gamma',
iter = 2000)
# Save the model output in a table
and_sum <- list(mod = and_mod)
and_sum$r2 <- bayes_R2(and_mod) # Bayesian R2
and_sum$MAE <- mae(and_mod, sub_data$Acre_feet) # Mean absolute error of model
# Look at posterior predictive check
pp_check(and_mod)
return(and_sum)
}
mods <- list()
names <- unique(div_new$Name)
for (i in names) {
data <- subset(div_new, Name == i)
if (length(data$Name) > 5){
mod_out <- mlr_brm(div_new, i)
mods[[i]] <- mod_out
}
}
library(brms) # work with outputs of GLMMs
library(bayesplot) # built in plots with brms
library(tidybayes) # get clean draws from brms object
library(modelr) # model manipulation for visualization
library(dplyr) # dataframe manipulation
library(tidyverse)
# Load the data and the model
df.arma <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/arma_input_0531.csv')
mod.arma <- readRDS('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/mod-arma-stud.RDS')
# Unscale function
unscale <- function(x, orig){
unscaled <- (sd(orig)*2*x)+mean(orig)
return(unscaled)
}
# Epreds for precipitaiton
print('Epreds for precipitaiton')
new = df.arma %>%
data_grid(scale_d.urb = mean(scale_d.urb),
scale_d.et = mean(scale_d.et),
scale_d.prcp = seq_range(scale_d.prcp, n = 200),
scale_d.temp = mean(scale_d.temp),
scale_d.use = mean(scale_d.use),
Year = Year)
new$Name <- NA
# Expected predicted draws
epreddraws <- add_epred_draws(mod.arma,
newdata=new,
ndraws=1000,
re_formula=NA)
epreddraws$unscale.prcp <- unscale(epreddraws$scale_d.prcp, df.arma$d.prcp)
print('success drawing predictions')
out_file <- paste('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_output/epred_prcp.csv')
write.csv(epreddraws, file = out_file)
## Import packages
library(brms)
library(Matrix)
library(tidyverse)
library(dplyr)
## Import data
div <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv')
div <- div[!duplicated(div[c('Name', 'Year')]),] #remove duplicates
div <- subset(div, (Acre_feet > 0.00001)) # Remove data that has 0
div_new <- subset(div, !(Name == 'Ester Simplot')) #Removes short dataframe
mae <- function(model, data_compare){
yhat <- (posterior_predict(model))
resid <- sweep(yhat,
2,
data_compare,
FUN="-")
return(mean(abs(resid)))
}
## Scaling function for variables
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
## Build function to run all diverisons through
mlr_brm <- function(data, name) {
#Subset data to an individual canal
sub_data <- subset(data, Name == name)
# Select only variables going into the model
sub_data <- sub_data[,c('Acre_feet',
'scale_class1_urban',
'annual_prcp',
'irrig_temp',
'et',
'AF_used')]
#Select variables to scale around mean
vars_scale <- c('annual_prcp',
'irrig_temp')
#Scale variables
for (i in vars_scale){
var_name <- i
sub_data[var_name] <- scale2sd(sub_data[,i])
}
# If storage water use is not 0, scale the variable
if (mean(sub_data$AF_used) != 0){
sub_data$AF_used <- scale2sd(sub_data$AF_used)
}
# Run the linear regression
and_mod<-brm(Acre_feet ~ scale_class1_urban + et + annual_prcp + irrig_temp + AF_used,
data=sub_data,
family = 'gamma',
iter = 2000)
# Save the model output in a table
and_sum <- list(mod = and_mod)
and_sum$r2 <- bayes_R2(and_mod) # Bayesian R2
and_sum$MAE <- mae(and_mod, sub_data$Acre_feet) # Mean absolute error of model
# Look at posterior predictive check
pp_check(and_mod)
return(and_sum)
}
mods <- list()
names <- unique(div_new$Name)
for (i in names) {
data <- subset(div_new, Name == i)
if (length(data$Name) > 5){
mod_out <- mlr_brm(div_new, i)
mods[[i]] <- mod_out
}
}
