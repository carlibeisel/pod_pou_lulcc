if (!is.null(mod_out)) {
mods[[i]] <- mod_out
}
} else {
message(paste("Not enough data points for:", i))
}
} else {
message(paste("Missing required columns for:", i))
}
}
# Run a for loop to determine best predictors and r-squared of model for each diversion
for (i in names) {
data <- subset(div_new, Name == i)
if (length(data$Name) > 5){
mod_out <- mlr_run(div_new, i)
mods[[i]] <- mod_out
}
}
# Function to find best model for each diversion
mlr_run <- function(data, name) {
#Subset data to an individual canal
sub_data <- subset(data, Name == name)
# Select only variables going into the model
sub_data <- sub_data[,c('Acre_feet',
'class1_urban',
'irrig_prcp',
'irrig_temp',
'et',
'AF_used',
'Carryover',
'ubrb_prcp',
'pivot_prop',
'sw_wr',
'gw_wr')]
#Select variables to scale around mean
vars_scale <- c('irrig_prcp', #changed from irrig_prcp
'irrig_temp')
#Scale variables
for (i in vars_scale){
var_name <- i
sub_data[var_name] <- scale2sd(sub_data[,i])
}
# If storage water use is not 0, scale the variable
if (mean(sub_data$AF_used) != 0){
sub_data$AF_used <- scale2sd(sub_data$AF_used)
}
# Use regsubsets to find model with lowest BIC
tryCatch({regsubsets.out<-regsubsets(sub_data$Acre_feet~., data=sub_data, nbest=1, nvmax=12)},
error= function(e) {print("Fit did not work")}) #error catch
reg_sum <- summary(regsubsets.out)
rm(regsubsets.out)
# Select variables from model with lowest BIC
vars<-reg_sum$which[which.min(reg_sum$bic),]
and_sum<- list(vars = names(vars)[vars==TRUE][-1], adjr2 = reg_sum$adjr2[which.min(reg_sum$bic)], bic=reg_sum$bic[which.min(reg_sum$bic)])
# Model formula
form<- paste("Acre_feet~ ", paste(and_sum$vars, collapse=" + "), sep = "")
# Run the linear regression
and_mod<-lm(form, data=sub_data)
# Save the adjusted R-squared in the summary table
and_sum$lm<-summary(and_mod)$adj.r.squared
and_sum$coef_val <- and_mod$coefficients
and_sum$pval <- summary(and_mod)$coefficients[,'Pr(>|t|)']
# Save summary of LOOCV
ctrl <- trainControl(method = 'LOOCV')
model <- train(as.formula(form), data = sub_data, method = "lm", trControl = ctrl)
and_sum$loocv<- model$results
mod.red<- resid(model)
and_sum$name <- name
plt_norm <- plot((model$pred$obs)/1000, (model$pred$pred)/1000, pch=19, xlab="Observed", ylab=name)
abline(0,1,col="gray50",lty=1)
return(and_sum)
}
# Pull names of all the diversions
names <- unique(div_new$Name)
mods <- list()
# Run a for loop to determine best predictors and r-squared of model for each diversion
for (i in names) {
data <- subset(div_new, Name == i)
if (length(data$Name) > 5){
mod_out <- mlr_run(div_new, i)
mods[[i]] <- mod_out
}
}
df <- data.frame(names)
df$prcp <- NA
df$prcp.coef <- NA
df$prcp.p <- NA
df$temp <- NA
df$temp.coef <-NA
df$temp.p <- NA
df$urb <- NA
df$urb.coef <- NA
df$urb.p <- NA
df$stor <- NA
df$stor.coef <- NA
df$stor.p <- NA
df$et <- NA
df$et.coef <- NA
df$et.p <- NA
df$adjr2 <- NA
df$ubrb_prcp <- NA
df$ubrb_prcp.coef <- NA
df$ubrb_prcp.p <- NA
df$sw_wr <- NA
df$sw_wr.coef <- NA
df$sw_wr.p <- NA
df$gw_wr <- NA
df$gw_wr.coef <- NA
df$gw_wr.p <- NA
df$carryover <- NA
df$carryover.coef <- NA
df$carryover.p <- NA
<- NA
for (i in 1:60) {
name <- names[i]
output <- mods[[i]]
vars <- output$vars
if ("AF_used" %in% vars) {
df[i, 'stor'] = 1
df[i, 'stor.coef'] = output$coef_val['AF_used']
pval = output$pval['AF_used']
if (pval < 0.05){
df[i, 'stor.p'] = 1
}
else{
df[i, 'stor.p'] = 0
}
}
else {
df[i,'stor'] = 0
}
if ("scale_class1_urban" %in% vars) {
df[i, 'urb'] = 1
df[i, 'urb.coef'] = output$coef_val['scale_class1_urban']
pval = output$pval['scale_class1_urban']
if (pval < 0.05){
df[i, 'urb.p'] = 1
}
else{
df[i, 'urb.p'] = 0
}
}
else {
df[i,'urb'] = 0
}
if ("irrig_prcp" %in% vars) {
df[i, 'prcp'] = 1
df[i, 'prcp.coef'] = output$coef_val['irrig_prcp']
pval = output$pval['irrig_prcp']
if (pval < 0.05){
df[i, 'prcp.p'] = 1
}
else{
df[i, 'prcp.p'] = 0
}
}
else {
df[i,'prcp'] = 0
}
if ("irrig_temp" %in% vars) {
df[i, 'temp'] = 1
df[i, 'temp.coef'] = output$coef_val['irrig_temp']
pval = output$pval['irrig_temp']
if (pval < 0.05){
df[i, 'temp.p'] = 1
}
else{
df[i, 'temp.p'] = 0
}
}
else {
df[i,'temp'] = 0
}
if ("et" %in% vars) {
df[i, 'et'] = 1
df[i, 'et.coef'] = output$coef_val['et']
pval = output$pval['et']
if (pval < 0.05){
df[i, 'et.p'] = 1
}
else{
df[i, 'et.p'] = 0
}
}
else {
df[i,'et'] = 0
}
adjr2 <- output$adjr2
df[i, 'adjr2'] <- adjr2
}
df$vars <- rowSums(df[,c('et', 'temp','prcp','urb','stor','sw_wr','gw_wr', 'ubrb_prcp', 'carryover')])
write.csv(df, file = '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/MLR_final_0822.csv')
library(brms)
library(bayesplot)
library(dplyr)
library(Matrix)
library(tidyverse)
library(tidybayes)
library(readr)
library(tibble)
library(ggrepel)
library(flexmix)
#install.packages('lattice')
library(modelr)
library(loo)
library(here)
#install.packages('tseries')
library(tseries)
#install.packages('urca')
library(urca) #kpss test
#install.packages('plm')
library(plm)
#install.packages('pracma')
library(pracma)
library(dplyr)
# Without zeros
data <- data.frame(read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0531.csv'))
# Without zeros
data <- data.frame(read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv'))
# Without zeros
data <- data.frame(read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv'))
data <- data[-c(1,6,37,38)] # drops Python index output with csv
data <- subset(data, select=-c(Month, DayofYear, Irrigation.Year, Sum, Diversion..cfs.))
data['Mar_et'][is.na(data['Mar_et'])] <- 0 #fill NA et values with 0
data['contagion'][is.na(data['contagion'])] <- 100 # fill NA contagion values with 100
nas <- data[rowSums(is.na(data)) > 0, ] #check for any data with remaining NA values
data <- na.omit(data)
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('class1_urban',
'class2_crops',
'contagion',
'largest_patch_index')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- (data[,i])/100
}
tt <- table(data$Name)
data <- subset(data, Name %in% names(tt[tt>4]))
write.csv(data, '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv', row.names = FALSE)
# With zeros data
data <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0822.csv')
data <- data[!duplicated(data[c('Name', 'Year')]),] #remove duplicates
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
# With zeros data
data <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0822.csv')
data <- data[!duplicated(data[c('Name', 'Year')]),] #remove duplicates
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
# With zeros data
data <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0822.csv')
data <- data[!duplicated(data[c('Name', 'Year')]),] #remove duplicates
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'annual_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
# Without zeros
data <- data.frame(read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv'))
data <- data[-c(1,6,37,38)] # drops Python index output with csv
data <- subset(data, select=-c(Month, DayofYear, Irrigation.Year, Sum, Diversion..cfs.))
data['Mar_et'][is.na(data['Mar_et'])] <- 0 #fill NA et values with 0
data['contagion'][is.na(data['contagion'])] <- 100 # fill NA contagion values with 100
nas <- data[rowSums(is.na(data)) > 0, ] #check for any data with remaining NA values
data <- na.omit(data)
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'irrig_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('class1_urban',
'class2_crops',
'contagion',
'largest_patch_index')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- (data[,i])/100
}
tt <- table(data$Name)
data <- subset(data, Name %in% names(tt[tt>4]))
write.csv(data, '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv', row.names = FALSE)
# With zeros data
data <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0822.csv')
data <- data[!duplicated(data[c('Name', 'Year')]),] #remove duplicates
scale2sd <- function(x){
(x - mean(x))/(sd(x)*2)
}
col_name <- c('ant_prcp',
'irrig_prcp',
'irrig_temp',
'JuneAug_temp',
'Mar_tmp',
'Mar_prcp',
'LP_inflows',
'Max_Fill',
'Carryover',
'AF_used',
'AF_remaining',
'AF_available',
'ubrb_prcp',
'sw_wr',
'gw_wr',
'total_wr',
'pivot_prop')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- scale2sd(data[,i])
}
col_name <- c('class1_urban',
'class2_crops',
'contagion',
'largest_patch_index')
for (i in col_name) {
name <- colnames(data[i])
new_col_name <- paste('scale_', name, sep = "")
data[new_col_name] <- (data[,i])/100
}
tt <- table(data$Name)
data <- subset(data, Name %in% names(tt[tt>4]))
# Storage data
data$perc_used <- ifelse(data$AF_available > 0, data$AF_used/data$AF_available, NA)
data$wr_storage <- ifelse(data$AF_available >0, 1, 0)
write.csv(data, '/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/mixed_model_input_0822.csv', row.names = FALSE)
# Import the dataset to work with
div <- read.csv('/Users/dbeisel/Desktop/DATA/Bridget/pod_pou_lulcc/model_input/input_full_0822.csv')
div$lt <- log(div$Acre_feet)
div_arma <- subset(div, (Acre_feet > 0.00001))
div_arma$lt <- log(div_arma$Acre_feet)
names <- unique(div_arma$Name)
# Find diversions with less than 34 years worth of data, and remove if there
# are data gaps, or if discharge for a given year in the middle was 0
for (i in names){
sub <- subset(div_arma, Name == i)
if (length(sub$Acre_feet) < 34){
print(i)
print(length(sub$Acre_feet))
}
}
remove <- c("Barber pumps",
"Mace-Mace Canal",
"River Run",
"Surprise Valley and Micron",
"Thomas Aiken Canal",
"Warm Springs Canal",
'Ester Simplot',
"Stutheit",
"Riverside Village",
"McCurry Pump",
"Golden Gate Canal",
"Capitol View Canal",
"Shakespeare",
"Suez")
div_arma <- subset(div_arma, !(Name %in% remove))
# Check after removal to ensure continuous datasets
names <- unique(div_arma$Name)
for (i in names){
sub <- subset(div_arma, Name == i)
if (length(sub$Acre_feet) < 34){
print(i)
print(length(sub$Acre_feet))
}
}
# Need change in a groups for a test, filter out groups with no change in urban proportion
ll.test <- div_arma %>%
group_by(Name) %>%
filter((max(class1_urban) - min(class1_urban)) > 0) %>%
ungroup()
# Need change in a groups for a test, filter out groups that use no storage over whole time period
# for stationarity test
ll.use <- div_arma %>%
group_by(Name) %>%
filter((max(AF_used) - min(AF_used)) > 0) %>%
ungroup()
# Panel dataframe for test
new_use <- pdata.frame(ll.use, index = c('Name', 'Year'))
new_use$AF_used <- as.numeric(new_use$AF_used) # change from integer to numeric for test
new_urb <- pdata.frame(ll.test, index = c('Name', 'Year'))
new <-pdata.frame(div_arma, index = c('Name', 'Year'))
urb.test <- purtest(new_urb$class1_urban, data = new_urb, lags = 'AIC', test = 'levinlin') #non-stationary
